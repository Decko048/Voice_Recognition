{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import scipy as sc\n",
    "from scipy import stats\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score,recall_score, f1_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,roc_curve,auc\n",
    "import seaborn as sns\n",
    "import numpy_indexed as npi\n",
    "\n",
    "class PIPELINE_MULTIPLES_INST:\n",
    "\n",
    "#################################################################################################################\n",
    "    def __init__(self,model,clases):\n",
    "        self.model = model\n",
    "        self.clases = clases\n",
    "#################################################################################################################\n",
    "    def modelPredict(self,model,Xtest,tracks_test):\n",
    "        Yest = model.predict(Xtest)    \n",
    "\n",
    "        #Creamos un matriz con la primera fila las predicciones y la otra el track      \n",
    "        X_test_with_id_trak = np.column_stack((Yest,tracks_test))\n",
    "\n",
    "        #Agrupamos por audio\n",
    "        prediction_by_instances = npi.group_by(X_test_with_id_trak[:, -1]).split(X_test_with_id_trak[:, -2])\n",
    "\n",
    "        #Sacamos la moda de prediccion\n",
    "        predictions = []\n",
    "\n",
    "        for v in range(len(prediction_by_instances)):\n",
    "            decision = stats.mode(prediction_by_instances[v])[0]\n",
    "            predictions.append(decision)\n",
    "    \n",
    "    return np.array(predictions) #Debe retornar un vector con las clases predichas para cada una de las muestras en Xtest, de acuerdo con los modelos almacenados en GMMs\n",
    "\n",
    "#################################################################################################################\n",
    "    def createGroups(self, Y,tracks):\n",
    "        Y_train_tracks = np.column_stack((Y,tracks))\n",
    "        groups_by_tracks = npi.group_by(Y_train_tracks[:, -1]).split(Y_train_tracks[:, -2])\n",
    "        modas = []\n",
    "\n",
    "        for v in range(len(groups_by_tracks)):\n",
    "            moda = stats.mode(groups_by_tracks[v])[0]\n",
    "            modas.append(moda)\n",
    "    return np.array(modas)\n",
    "#################################################################################################################\n",
    "    def TRAIN(self, model,X_train,Y_train,tracks_train,train_size,folds,groups_train):\n",
    "        gss = GroupShuffleSplit(n_splits=folds, train_size=.7)\n",
    "        EficienciaTrain = np.zeros(folds)\n",
    "        EficienciaVal = np.zeros(folds)\n",
    "        j = 0\n",
    "\n",
    "\n",
    "        for train_idx, test_idx in gss.split(X_train, Y_train, groups_train):\n",
    "\n",
    "            X_train_fold =X_train[train_idx]\n",
    "            Y_train_fold=Y_train[train_idx]\n",
    "            X_test_fold=X_train[test_idx]\n",
    "            Y_test_fold=Y_train[test_idx]\n",
    "\n",
    "            tracks_train_fold=tracks_train[train_idx]\n",
    "            tracks_test_fold=tracks_train[test_idx]\n",
    "\n",
    "            #Entrenamiento\n",
    "            model.fit(X_train_fold)\n",
    "\n",
    "             #Validación\n",
    "            Ytrain_pred = self.modelPredict(model,X_train_fold,tracks_train_fold)\n",
    "\n",
    "            Ytest_pred = self.modelPredict(model,X_test_fold,tracks_test_fold)\n",
    "\n",
    "\n",
    "            #Metricas en entrenamiento\n",
    "\n",
    "            #Hacer groupby por tracks\n",
    "            Y_real_train = self.createGroups(Y_train_fold,tracks_train_fold)\n",
    "            Y_real_test = self.createGroups(Y_test_fold,tracks_test_fold)\n",
    "\n",
    "            \"\"\"\n",
    "            print('TRAIN')\n",
    "            print('Predicted',Ytrain_pred )\n",
    "            print('Real',Y_real_train)\n",
    "\n",
    "            print('----------------')\n",
    "            print('TEST')\n",
    "            print('Predicted',Ytest_pred)\n",
    "            print('Real',Y_real_test)\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "            EficienciaTrain[j] = np.mean(Ytrain_pred.ravel() == Y_real_train.ravel())\n",
    "            EficienciaVal[j] = np.mean(Ytest_pred.ravel() == Y_real_test.ravel())\n",
    "            j += 1\n",
    "\n",
    "        eficiencia_Train=(np.mean(EficienciaTrain))\n",
    "        intervalo_Train=(np.std(EficienciaTrain))\n",
    "        eficiencia_Test=np.mean(EficienciaVal)\n",
    "        intervalo_Test=np.std(EficienciaVal)\n",
    "        #print('Eficiencia durante el entrenamiento = ' + str(eficiencia_Train) + '+-' + str(intervalo_Train))\n",
    "        #print('Eficiencia durante la validación = ' + str(eficiencia_Test) + '+-' + str(intervalo_Test)) \n",
    "        #Se retorna el modelo del ultimo fold\n",
    "    return model,eficiencia_Train,intervalo_Train,eficiencia_Test,intervalo_Test\n",
    "#################################################################################################################\n",
    "\n",
    "    def confusion_matrix_Metrics(self, model,Xtest,Ytest,groupsTest,tracksTest,clases):\n",
    "\n",
    "        Ytest_pred= self.modelPredict(self,model,Xtest,tracksTest)\n",
    "\n",
    "\n",
    "        Y_real_test = self.createGroups(self,Ytest,tracksTest)\n",
    "\n",
    "        print('Accuracy: ', accuracy_score(Y_real_test, Ytest_pred), '\\n')\n",
    "        report = classification_report(Y_real_test, Ytest_pred)\n",
    "        print(\"\\nclassification report :\\n\",report )\n",
    "\n",
    "        # Matriz de confusión\n",
    "        cm = confusion_matrix(Y_real_test, Ytest_pred)\n",
    "        cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        fig, ax = plt.subplots(figsize=(10,10))\n",
    "        sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=clases, yticklabels=clases)\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        ax.set_ylim(sorted(ax.get_xlim(), reverse=True))\n",
    "        plt.show(block=False)\n",
    "        return report\n",
    "#################################################################################################################\n",
    "\n",
    "    def learning_curve(self, model,folds, X,Y,groups,tracks, suptitle='', title='', xlabel='Training Set Size', ylabel='Acurracy'):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        suptitle : str\n",
    "            Chart suptitle\n",
    "        title: str\n",
    "            Chart title\n",
    "        xlabel: str\n",
    "            Label for the X axis\n",
    "        ylabel: str\n",
    "            Label for the y axis\n",
    "        Returns\n",
    "        -------\n",
    "        Plot of learning curves\n",
    "        \"\"\"\n",
    "\n",
    "        # create lists to store train and validation scores\n",
    "        train_score = []\n",
    "        val_score = []\n",
    "        std_train= []\n",
    "        std_val=[]\n",
    "\n",
    "        # create ten incremental training set sizes\n",
    "        training_set_sizes = np.linspace(.1,.9,5).tolist()\n",
    "        # for each one of those training set sizes\n",
    "\n",
    "        for i in training_set_sizes:  \n",
    "                    \n",
    "            \n",
    "            model, eficiencia_Train,intervalo_Train,eficiencia_Test,intervalo_Test=self.TRAIN(model,X,Y,tracks,i,folds,groups)\n",
    "            \n",
    "            \n",
    "            # store the scores in their respective lists\n",
    "            train_score.append(eficiencia_Train)\n",
    "            val_score.append(eficiencia_Test)\n",
    "            std_train.append(intervalo_Train)\n",
    "            std_val.append(intervalo_Test)\n",
    "\n",
    "        train_score =np.array(train_score)\n",
    "        val_score =np.array(val_score)\n",
    "        std_train =np.array(std_train)\n",
    "        std_val =np.array(std_val)\n",
    "\n",
    "\n",
    "        # plot learning curves\n",
    "        fig, ax = plt.subplots(figsize=(14, 9))\n",
    "        ax.plot(training_set_sizes, train_score, c='gold')\n",
    "        ax.plot(training_set_sizes, val_score, c='steelblue')\n",
    "\n",
    "        ax.fill_between(training_set_sizes,train_score+std_train,train_score-std_train,facecolor='gold',alpha=0.5)\n",
    "        ax.fill_between(training_set_sizes,val_score+std_val,val_score-std_val,facecolor='steelblue',alpha=0.5)\n",
    "\n",
    "        # format the chart to make it look nice\n",
    "        fig.suptitle(suptitle, fontweight='bold', fontsize='20')\n",
    "        ax.set_title(title, size=20)\n",
    "        ax.set_xlabel(xlabel, size=16)\n",
    "        ax.set_ylabel(ylabel, size=16)\n",
    "        ax.legend(['Train set', 'Test set'], fontsize=16)\n",
    "        ax.tick_params(axis='both', labelsize=12)\n",
    "        ax.set_ylim(0, 1)\n",
    "\n",
    "        def percentages(x, pos):\n",
    "            \"\"\"The two args are the value and tick position\"\"\"\n",
    "            if x < 1:\n",
    "                return '{:1.0f}'.format(x*100)\n",
    "            return '{:1.0f}%'.format(x*100)\n",
    "\n",
    "        def numbers(x, pos):\n",
    "            \"\"\"The two args are the value and tick position\"\"\"\n",
    "            if x >= 1000:\n",
    "                return '{:1,.0f}'.format(x)\n",
    "            return '{:1.0f}'.format(x)\n",
    "        data = {'Train_Size':training_set_sizes, 'mean_train_Accuracy':train_score,'mean_test_Accuracy':val_score,'std_train_Accuracy':std_train,'std_test_Accuracy':std_val}\n",
    "        df_split_params = pd.DataFrame(data)\n",
    "        return df_split_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
