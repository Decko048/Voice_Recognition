{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from METRICS import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import scipy as sc\n",
    "from scipy import stats\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score,recall_score, f1_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,roc_curve,auc\n",
    "import seaborn as sns\n",
    "import numpy_indexed as npi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model, parameters, folds, train_size, X,Y,groups_original):\n",
    "    acc_scorer = make_scorer(accuracy_score)\n",
    "    recalls = make_scorer(recall_score,average='micro')##buscar por que micro\n",
    "    precision = make_scorer(precision_score,average='micro')\n",
    "    f1 = make_scorer(f1_score,average='micro')\n",
    "    scores =  {'recalls':recalls,'precision':precision,'f1':f1,'Accuracy': make_scorer(accuracy_score)}\n",
    "    gss = GroupShuffleSplit(n_splits=folds, train_size=train_size, random_state=0)\n",
    "    model = GridSearchCV(model,parameters,scores,-1,refit='Accuracy',return_train_score=True, cv=gss.split(X, Y, groups=groups_original))\n",
    "    model.fit(X,Y)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Metrics(model,X_test,Y_test,clases):\n",
    "\n",
    "  y_predicted = model.predict(X_test)\n",
    "  print('Accuracy: ', accuracy_score(Y_test, y_predicted), '\\n')\n",
    "  report = classification_report(Y_test, y_predicted)\n",
    "  print(\"\\nclassification report :\\n\",report )\n",
    " \n",
    "  # Matriz de confusión\n",
    "  cm = confusion_matrix(Y_test, y_predicted)\n",
    "  # Normalise\n",
    "  cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "  fig, ax = plt.subplots(figsize=(10,10))\n",
    "    \n",
    "  sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=clases, yticklabels=clases)\n",
    "  plt.ylabel('Actual')\n",
    "  plt.xlabel('Predicted')\n",
    "  ax.set_ylim(sorted(ax.get_xlim(), reverse=True))\n",
    "  plt.show(block=False)\n",
    "  \n",
    "  #sns.heatmap(cm,annot=True,fmt = \"d\",linecolor=\"k\",linewidths=3)\n",
    "  #plt.title(\"Matriz de confusión\",fontsize=20)\n",
    "   \n",
    "    \n",
    "  return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_curve(model,best_parameters,folds, X,Y,groups=groups, suptitle='', title='', xlabel='Training Set Size', ylabel='Acurracy'):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    suptitle : str\n",
    "        Chart suptitle\n",
    "    title: str\n",
    "        Chart title\n",
    "    xlabel: str\n",
    "        Label for the X axis\n",
    "    ylabel: str\n",
    "        Label for the y axis\n",
    "    Returns\n",
    "    -------\n",
    "    Plot of learning curves\n",
    "    \"\"\"\n",
    "    \n",
    "    # create lists to store train and validation scores\n",
    "    train_score = []\n",
    "    val_score = []\n",
    "    std_train= []\n",
    "    std_val=[]\n",
    "\n",
    "    # create ten incremental training set sizes\n",
    "    training_set_sizes = np.linspace(.1,.9,5).tolist()\n",
    "    # for each one of those training set sizes\n",
    "    \n",
    "    for i in training_set_sizes:  \n",
    "        model_trained = build_model(model=model, parameters=best_parameters, folds=folds, train_size=i, X=X,Y=Y,groups_original=groups_original)                \n",
    "        EfficiencyVal= model_trained.cv_results_['mean_test_Accuracy'][model_trained.best_index_]\n",
    "        EfficiencyTrain=model_trained.cv_results_['mean_train_Accuracy'][model_trained.best_index_]\n",
    "        stdTrain=model_trained.cv_results_['std_train_Accuracy'][model_trained.best_index_]\n",
    "        stdVal=model_trained.cv_results_['std_test_Accuracy'][model_trained.best_index_]\n",
    "\n",
    "        # store the scores in their respective lists\n",
    "        train_score.append(EfficiencyTrain)\n",
    "        val_score.append(EfficiencyVal)\n",
    "        std_train.append(stdTrain)\n",
    "        std_val.append(stdVal)\n",
    "\n",
    "    train_score =np.array(train_score)\n",
    "    val_score =np.array(val_score)\n",
    "    std_train =np.array(std_train)\n",
    "    std_val =np.array(std_val)\n",
    "\n",
    "\n",
    "    # plot learning curves\n",
    "    fig, ax = plt.subplots(figsize=(14, 9))\n",
    "    ax.plot(training_set_sizes, train_score, c='gold')\n",
    "    ax.plot(training_set_sizes, val_score, c='steelblue')\n",
    "    \n",
    "    ax.fill_between(training_set_sizes,train_score+std_train,train_score-std_train,facecolor='gold',alpha=0.5)\n",
    "    ax.fill_between(training_set_sizes,val_score+std_val,val_score-std_val,facecolor='steelblue',alpha=0.5)\n",
    "\n",
    "    # format the chart to make it look nice\n",
    "    fig.suptitle(suptitle, fontweight='bold', fontsize='20')\n",
    "    ax.set_title(title, size=20)\n",
    "    ax.set_xlabel(xlabel, size=16)\n",
    "    ax.set_ylabel(ylabel, size=16)\n",
    "    ax.legend(['Train set', 'Test set'], fontsize=16)\n",
    "    ax.tick_params(axis='both', labelsize=12)\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "    def percentages(x, pos):\n",
    "        \"\"\"The two args are the value and tick position\"\"\"\n",
    "        if x < 1:\n",
    "            return '{:1.0f}'.format(x*100)\n",
    "        return '{:1.0f}%'.format(x*100)\n",
    "\n",
    "    def numbers(x, pos):\n",
    "        \"\"\"The two args are the value and tick position\"\"\"\n",
    "        if x >= 1000:\n",
    "            return '{:1,.0f}'.format(x)\n",
    "        return '{:1.0f}'.format(x)\n",
    "    data = {'Train_Size':training_set_sizes, 'mean_train_Accuracy':train_score,'mean_test_Accuracy':val_score,'std_train_Accuracy':std_train,'std_test_Accuracy':std_val}\n",
    "    df_split_params = pd.DataFrame(data)\n",
    "    return df_split_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-578.183594</td>\n",
       "      <td>34.746494</td>\n",
       "      <td>-6.227449</td>\n",
       "      <td>50.076725</td>\n",
       "      <td>13.485531</td>\n",
       "      <td>20.483133</td>\n",
       "      <td>23.309504</td>\n",
       "      <td>17.892561</td>\n",
       "      <td>22.907711</td>\n",
       "      <td>19.530531</td>\n",
       "      <td>...</td>\n",
       "      <td>18.488085</td>\n",
       "      <td>16.491943</td>\n",
       "      <td>20.265697</td>\n",
       "      <td>15.504094</td>\n",
       "      <td>17.719561</td>\n",
       "      <td>16.063190</td>\n",
       "      <td>7.158887</td>\n",
       "      <td>15.391005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-539.838135</td>\n",
       "      <td>39.440987</td>\n",
       "      <td>-18.157864</td>\n",
       "      <td>56.610138</td>\n",
       "      <td>13.561887</td>\n",
       "      <td>27.468927</td>\n",
       "      <td>22.405123</td>\n",
       "      <td>18.649464</td>\n",
       "      <td>20.244602</td>\n",
       "      <td>15.674647</td>\n",
       "      <td>...</td>\n",
       "      <td>22.015572</td>\n",
       "      <td>11.824497</td>\n",
       "      <td>19.782654</td>\n",
       "      <td>15.595941</td>\n",
       "      <td>14.123998</td>\n",
       "      <td>15.435017</td>\n",
       "      <td>12.188399</td>\n",
       "      <td>15.958430</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-633.009155</td>\n",
       "      <td>46.591732</td>\n",
       "      <td>31.916828</td>\n",
       "      <td>24.640398</td>\n",
       "      <td>20.384712</td>\n",
       "      <td>21.708477</td>\n",
       "      <td>21.421858</td>\n",
       "      <td>23.832544</td>\n",
       "      <td>24.445465</td>\n",
       "      <td>21.587992</td>\n",
       "      <td>...</td>\n",
       "      <td>13.741821</td>\n",
       "      <td>17.604811</td>\n",
       "      <td>20.631048</td>\n",
       "      <td>20.548290</td>\n",
       "      <td>17.002838</td>\n",
       "      <td>13.849539</td>\n",
       "      <td>13.543025</td>\n",
       "      <td>13.759918</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-452.937225</td>\n",
       "      <td>125.244095</td>\n",
       "      <td>43.845169</td>\n",
       "      <td>91.930519</td>\n",
       "      <td>21.001598</td>\n",
       "      <td>14.252425</td>\n",
       "      <td>5.181086</td>\n",
       "      <td>23.042732</td>\n",
       "      <td>-7.787588</td>\n",
       "      <td>-7.302704</td>\n",
       "      <td>...</td>\n",
       "      <td>16.110474</td>\n",
       "      <td>12.235356</td>\n",
       "      <td>16.800062</td>\n",
       "      <td>10.826190</td>\n",
       "      <td>8.179255</td>\n",
       "      <td>7.419957</td>\n",
       "      <td>3.597054</td>\n",
       "      <td>8.044436</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-563.710693</td>\n",
       "      <td>79.472610</td>\n",
       "      <td>35.141331</td>\n",
       "      <td>58.115299</td>\n",
       "      <td>40.987614</td>\n",
       "      <td>32.446346</td>\n",
       "      <td>15.186209</td>\n",
       "      <td>34.812389</td>\n",
       "      <td>11.014744</td>\n",
       "      <td>3.695235</td>\n",
       "      <td>...</td>\n",
       "      <td>12.510882</td>\n",
       "      <td>12.819203</td>\n",
       "      <td>13.827777</td>\n",
       "      <td>14.294342</td>\n",
       "      <td>10.434172</td>\n",
       "      <td>9.369196</td>\n",
       "      <td>9.179496</td>\n",
       "      <td>10.365860</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>-539.770508</td>\n",
       "      <td>79.760132</td>\n",
       "      <td>24.791115</td>\n",
       "      <td>27.663658</td>\n",
       "      <td>17.612919</td>\n",
       "      <td>30.274504</td>\n",
       "      <td>19.307281</td>\n",
       "      <td>21.242352</td>\n",
       "      <td>15.312921</td>\n",
       "      <td>9.133543</td>\n",
       "      <td>...</td>\n",
       "      <td>13.179388</td>\n",
       "      <td>12.752730</td>\n",
       "      <td>17.898590</td>\n",
       "      <td>12.665988</td>\n",
       "      <td>10.535906</td>\n",
       "      <td>11.531238</td>\n",
       "      <td>9.660569</td>\n",
       "      <td>14.150393</td>\n",
       "      <td>1.0</td>\n",
       "      <td>609.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>-539.998535</td>\n",
       "      <td>148.162888</td>\n",
       "      <td>61.355381</td>\n",
       "      <td>15.081635</td>\n",
       "      <td>11.361095</td>\n",
       "      <td>10.008124</td>\n",
       "      <td>3.340254</td>\n",
       "      <td>3.150235</td>\n",
       "      <td>6.168007</td>\n",
       "      <td>8.034798</td>\n",
       "      <td>...</td>\n",
       "      <td>3.662930</td>\n",
       "      <td>12.336813</td>\n",
       "      <td>4.206754</td>\n",
       "      <td>-6.095991</td>\n",
       "      <td>-1.812998</td>\n",
       "      <td>8.413839</td>\n",
       "      <td>12.013117</td>\n",
       "      <td>12.154606</td>\n",
       "      <td>1.0</td>\n",
       "      <td>610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>-575.798157</td>\n",
       "      <td>109.206421</td>\n",
       "      <td>40.084347</td>\n",
       "      <td>2.207824</td>\n",
       "      <td>6.494443</td>\n",
       "      <td>19.620073</td>\n",
       "      <td>16.461866</td>\n",
       "      <td>-2.157397</td>\n",
       "      <td>-21.011055</td>\n",
       "      <td>-24.194643</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.410588</td>\n",
       "      <td>4.623737</td>\n",
       "      <td>-1.226568</td>\n",
       "      <td>15.206586</td>\n",
       "      <td>16.772701</td>\n",
       "      <td>3.964441</td>\n",
       "      <td>11.726809</td>\n",
       "      <td>11.859737</td>\n",
       "      <td>1.0</td>\n",
       "      <td>610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>-549.157654</td>\n",
       "      <td>131.149902</td>\n",
       "      <td>38.933079</td>\n",
       "      <td>-7.734122</td>\n",
       "      <td>-10.893186</td>\n",
       "      <td>-12.604925</td>\n",
       "      <td>-15.898232</td>\n",
       "      <td>-4.690342</td>\n",
       "      <td>14.742783</td>\n",
       "      <td>23.064165</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.161046</td>\n",
       "      <td>29.092978</td>\n",
       "      <td>36.631687</td>\n",
       "      <td>21.981638</td>\n",
       "      <td>15.151622</td>\n",
       "      <td>10.731631</td>\n",
       "      <td>1.915951</td>\n",
       "      <td>6.023498</td>\n",
       "      <td>1.0</td>\n",
       "      <td>610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>-328.492188</td>\n",
       "      <td>199.579544</td>\n",
       "      <td>-9.542044</td>\n",
       "      <td>21.637730</td>\n",
       "      <td>-13.446092</td>\n",
       "      <td>5.755135</td>\n",
       "      <td>-5.299373</td>\n",
       "      <td>-15.437536</td>\n",
       "      <td>-6.194932</td>\n",
       "      <td>0.699006</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326036</td>\n",
       "      <td>-14.855879</td>\n",
       "      <td>-8.119945</td>\n",
       "      <td>2.179769</td>\n",
       "      <td>-1.196584</td>\n",
       "      <td>16.477579</td>\n",
       "      <td>23.693008</td>\n",
       "      <td>11.178597</td>\n",
       "      <td>1.0</td>\n",
       "      <td>610.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0           1          2          3          4          5    \\\n",
       "0    -578.183594   34.746494  -6.227449  50.076725  13.485531  20.483133   \n",
       "1    -539.838135   39.440987 -18.157864  56.610138  13.561887  27.468927   \n",
       "2    -633.009155   46.591732  31.916828  24.640398  20.384712  21.708477   \n",
       "3    -452.937225  125.244095  43.845169  91.930519  21.001598  14.252425   \n",
       "4    -563.710693   79.472610  35.141331  58.115299  40.987614  32.446346   \n",
       "...          ...         ...        ...        ...        ...        ...   \n",
       "4995 -539.770508   79.760132  24.791115  27.663658  17.612919  30.274504   \n",
       "4996 -539.998535  148.162888  61.355381  15.081635  11.361095  10.008124   \n",
       "4997 -575.798157  109.206421  40.084347   2.207824   6.494443  19.620073   \n",
       "4998 -549.157654  131.149902  38.933079  -7.734122 -10.893186 -12.604925   \n",
       "4999 -328.492188  199.579544  -9.542044  21.637730 -13.446092   5.755135   \n",
       "\n",
       "            6          7          8          9    ...        192        193  \\\n",
       "0     23.309504  17.892561  22.907711  19.530531  ...  18.488085  16.491943   \n",
       "1     22.405123  18.649464  20.244602  15.674647  ...  22.015572  11.824497   \n",
       "2     21.421858  23.832544  24.445465  21.587992  ...  13.741821  17.604811   \n",
       "3      5.181086  23.042732  -7.787588  -7.302704  ...  16.110474  12.235356   \n",
       "4     15.186209  34.812389  11.014744   3.695235  ...  12.510882  12.819203   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "4995  19.307281  21.242352  15.312921   9.133543  ...  13.179388  12.752730   \n",
       "4996   3.340254   3.150235   6.168007   8.034798  ...   3.662930  12.336813   \n",
       "4997  16.461866  -2.157397 -21.011055 -24.194643  ...  -1.410588   4.623737   \n",
       "4998 -15.898232  -4.690342  14.742783  23.064165  ...  -1.161046  29.092978   \n",
       "4999  -5.299373 -15.437536  -6.194932   0.699006  ...  -0.326036 -14.855879   \n",
       "\n",
       "            194        195        196        197        198        199  200  \\\n",
       "0     20.265697  15.504094  17.719561  16.063190   7.158887  15.391005  4.0   \n",
       "1     19.782654  15.595941  14.123998  15.435017  12.188399  15.958430  4.0   \n",
       "2     20.631048  20.548290  17.002838  13.849539  13.543025  13.759918  4.0   \n",
       "3     16.800062  10.826190   8.179255   7.419957   3.597054   8.044436  4.0   \n",
       "4     13.827777  14.294342  10.434172   9.369196   9.179496  10.365860  4.0   \n",
       "...         ...        ...        ...        ...        ...        ...  ...   \n",
       "4995  17.898590  12.665988  10.535906  11.531238   9.660569  14.150393  1.0   \n",
       "4996   4.206754  -6.095991  -1.812998   8.413839  12.013117  12.154606  1.0   \n",
       "4997  -1.226568  15.206586  16.772701   3.964441  11.726809  11.859737  1.0   \n",
       "4998  36.631687  21.981638  15.151622  10.731631   1.915951   6.023498  1.0   \n",
       "4999  -8.119945   2.179769  -1.196584  16.477579  23.693008  11.178597  1.0   \n",
       "\n",
       "        201  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       1.0  \n",
       "3       3.0  \n",
       "4       3.0  \n",
       "...     ...  \n",
       "4995  609.0  \n",
       "4996  610.0  \n",
       "4997  610.0  \n",
       "4998  610.0  \n",
       "4999  610.0  \n",
       "\n",
       "[5000 rows x 202 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATHDATA_MFFC_AVG = '../../data/audios_MFCC_Flatten_Means.csv'\n",
    "df = pd.read_csv(PATHDATA_MFFC_AVG, header = None)\n",
    "clases =np.array(['yes','no','right','five','nine'])\n",
    "data = df.values #Convertimos en un  numpy array\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño data set (5000, 199)\n"
     ]
    }
   ],
   "source": [
    "X = data[:,0:-3]\n",
    "Y = data[:,-2]\n",
    "print('Tamaño data set', X.shape)\n",
    "\n",
    "Y=  np.reshape(Y,(np.size(Y,0),1))\n",
    "groups = data[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de hablantes diferentes 668\n"
     ]
    }
   ],
   "source": [
    "n_groups = len(np.unique(groups))\n",
    "print('Número de hablantes diferentes', n_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "gss.get_n_splits()\n",
    "for train_index, test_index in gss.split(X, Y, groups=groups):\n",
    "    X_train_original, X_test__original = X[train_index], X[test_index]\n",
    "    #print(X_train, X_test)\n",
    "    Y_train__original, Y_test__original = Y[train_index], Y[test_index]\n",
    "    #print(y_train, y_test)\n",
    "    groups_original = groups[train_index]\n",
    "    groups_test_original=groups[test_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS = 10\n",
    "TRAIN_SIZE = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deiry/semilleroML/semillero/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_layer_sizes': (40, 40, 40, 40)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "parameters = [{'hidden_layer_sizes': [(32,32),(36,36),(40,40)]},\n",
    "{'hidden_layer_sizes': [(32,32,32),(36,36,36),(40,40,40)]},\n",
    "{'hidden_layer_sizes': [(32,32,32,32),(36,36,36,36),(40,40,40,40)]}]\n",
    "mlp = MLPClassifier()#Configurar el modelo\n",
    "model_trained_MLP = METRICS.build_model(self=1, model=mlp, parameters=parameters,folds=FOLDS,train_size=TRAIN_SIZE, X=X_train_original,Y=Y_train__original,groups_original=groups_original)\n",
    "best_params_MLP = model_trained_MLP.cv_results_['params'][model_trained_MLP.best_index_]\n",
    "print(best_params_MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados mejor modelo:  {'hidden_layer_sizes': (40, 40, 40, 40)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'mean_train_Accuracy': 0.9915770081830482},\n",
       " {'mean_test_Accuracy': 0.7976773215343351},\n",
       " {'std_train_Accuracy': 0.009857491606200336},\n",
       " {'std_test_Accuracy': 0.012218688733500111}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_acurracy = ['mean_train_Accuracy','mean_test_Accuracy','std_train_Accuracy','std_test_Accuracy']\n",
    "best_acurracy_MLP= []\n",
    "for p in params_acurracy:\n",
    "    parameter_acurracy =model_trained_MLP.cv_results_[p][model_trained_MLP.best_index_]\n",
    "    best_acurracy_MLP.append({p:parameter_acurracy})\n",
    "print(\"Resultados mejor modelo: \", best_params_MLP)\n",
    "best_acurracy_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7986501687289089 \n",
      "\n",
      "\n",
      "classification report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.74      0.76       170\n",
      "         1.0       0.64      0.76      0.69       181\n",
      "         2.0       0.84      0.79      0.82       185\n",
      "         3.0       0.81      0.79      0.80       189\n",
      "         4.0       0.97      0.93      0.95       164\n",
      "\n",
      "    accuracy                           0.80       889\n",
      "   macro avg       0.81      0.80      0.80       889\n",
      "weighted avg       0.81      0.80      0.80       889\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MLP_best_estimator = model_trained_MLP.best_estimator_\n",
    "metrics = Metrics(MLP_best_estimator,X_test__original,Y_test__original,clases)\n",
    "#metricsF = Metrics(self=1,model=MLP_best_estimator,X_test=X_test__original,Y_test=Y_test__original,tracks_test=tracks_test_original,clases=clases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deiry/semilleroML/semillero/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-3ef5e26fde2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbest_params_MLP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'hidden_layer_sizes'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_params_MLP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hidden_layer_sizes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_split_params\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mMETRICS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMETRICS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMLP_best_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_params_MLP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/semilleroML/Voice_Recognition/pipelines/Enfoque_Tradicional_Flatten_Means/METRICS.py\u001b[0m in \u001b[0;36mlearning_curve\u001b[0;34m(self, model, best_parameters, folds, X, Y, groups, suptitle, title, xlabel, ylabel)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;31m# for each one of those training set sizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_set_sizes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0mmodel_trained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgroups_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mEfficiencyVal\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel_trained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_test_Accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_trained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_index_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/semilleroML/Voice_Recognition/pipelines/Enfoque_Tradicional_Flatten_Means/METRICS.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(self, model, parameters, folds, train_size, X, Y, groups_original)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mgss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGroupShuffleSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups_original\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/semilleroML/semillero/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/semilleroML/semillero/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    993\u001b[0m         \"\"\"\n\u001b[1;32m    994\u001b[0m         return self._fit(X, y, incremental=(self.warm_start and\n\u001b[0;32m--> 995\u001b[0;31m                                             hasattr(self, \"classes_\")))\n\u001b[0m\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/semilleroML/semillero/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    341\u001b[0m                                            incremental):\n\u001b[1;32m    342\u001b[0m             \u001b[0;31m# First time training the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;31m# lbfgs does not support mini-batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/semilleroML/semillero/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, y, layer_units)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             coef_init, intercept_init = self._init_coef(layer_units[i],\n\u001b[0;32m--> 284\u001b[0;31m                                                         layer_units[i + 1])\n\u001b[0m\u001b[1;32m    285\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefs_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercepts_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/semilleroML/semillero/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_init_coef\u001b[0;34m(self, fan_in, fan_out)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'logistic'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mfactor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0minit_bound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactor\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfan_in\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfan_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# Generate weights and bias:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'list'"
     ]
    }
   ],
   "source": [
    "best_params_MLP = {'hidden_layer_sizes' : [(best_params_MLP['hidden_layer_sizes'])]}\n",
    "\n",
    "df_split_params =METRICS.learning_curve(METRICS,MLP_best_estimator,best_params_MLP,10, X,Y,groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
