{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MÃ©todo build_features('SamplesPath.txt', arraywords(Y)) \n",
    "\n",
    "Parametros: un array con las palabra y el path del archivo que contiene las rutas de los audios analizar\n",
    "\n",
    "Retorna: Matriz con #filas: cantidad de audios, #columna: cantidad de bloques por audio +2 columnas adicionales donde en la primera es la clase a la que pertenece y la segunda es el id del hablante\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipynb\n",
      "  Downloading https://files.pythonhosted.org/packages/31/42/4c0bbb66390e3a68e04ebf134c8d074a00c18b5882293f8ace5f7497fbf0/ipynb-0.5.1-py3-none-any.whl\n",
      "Installing collected packages: ipynb\n",
      "Successfully installed ipynb-0.5.1\n"
     ]
    }
   ],
   "source": [
    "! pip install ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from get_features_audio import GETFEATURES\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREAR DATASET PARA ENTRENAR Y VALIDAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(PATHSAMPLES, SOUNDS):\n",
    "    GF = GETFEATURES()\n",
    "    ROOTPATH= 'data/'\n",
    "    data = pd.read_csv(PATHSAMPLES, sep=\" \", header=None)\n",
    "    data = data.values #Convertir en numpy array\n",
    "    labels = []\n",
    "    speakers  = []\n",
    "    paths = []\n",
    "    DIVISIONROW, DIVISIONCOL = 9,9\n",
    "    for path in data:\n",
    "        pathSplit =path[0].split('/')\n",
    "        speakerName = pathSplit[1].split('_')[0]\n",
    "        word = pathSplit[0]\n",
    "        isWord = np.where(SOUNDS == word)\n",
    "        if len(isWord[0]) != 0:\n",
    "            label = SOUNDS[isWord[0][0]]\n",
    "            labels.append(label)\n",
    "            speakers.append(speakerName)\n",
    "            paths.append(ROOTPATH+path[0])\n",
    "    \n",
    "    #bloques y ademas una columna para la etiqueta o sonido que represente y otra para el id del hablante\n",
    "    #NUMERO DE MUESTRAS POR CLASE\n",
    "    NSAMPLES = 1300\n",
    "    first = labels.index(SOUNDS[0])\n",
    "    last = first +NSAMPLES\n",
    "    matrixMajor = np.column_stack([paths[first:last], labels[first:last], speakers[first:last]])    \n",
    "    for i in range(1,np.size(SOUNDS,0)):\n",
    "        first = labels.index(SOUNDS[i])\n",
    "        last = first +NSAMPLES\n",
    "        clasei = np.column_stack([paths[first:last], labels[first:last], speakers[first:last]])    \n",
    "        matrixMajor = np.append(matrixMajor,clasei,axis=0)\n",
    "        # Contienes todos los paths , palabra y idSpeaker de 1300 por clase\n",
    "    \n",
    "    \n",
    "    rows = matrixMajor.shape[0] # numero de filas es la cantidad de audios \n",
    "    colums = DIVISIONROW*DIVISIONCOL*2+2 # cantidad de bloques por 2 ya que esta la media y std de todos los \n",
    "    \n",
    "    #Recorre la matriz, importar el metodo get_features_audio del archivo get_features_audio, extraer las 5200 features, codificar la columna de label y guardad en un archivo\n",
    "    matrixFeatures = np.ones((rows,colums))\n",
    "    cont = 0\n",
    "    #Encode etiqueta del audio y el speaker\n",
    "    leLabel = preprocessing.LabelEncoder()\n",
    "    leLabel.fit(matrixMajor[:,1])\n",
    "    leSpeaker = preprocessing.LabelEncoder()\n",
    "    leSpeaker.fit(matrixMajor[:,2])\n",
    "    #----------------------\n",
    "    \n",
    "    for infoSound in matrixMajor:\n",
    "        feat = GF.get_features_audios(infoSound[0], DIVISIONROW, DIVISIONCOL)\n",
    "        label = infoSound[1]\n",
    "        speaker = infoSound[2]\n",
    "        labelN = leLabel.transform([label])\n",
    "        labelS = leSpeaker.transform([speaker])\n",
    "        matrixFeatures[cont][0:colums-2]=feat\n",
    "        matrixFeatures[cont][-2]=labelS[0]\n",
    "        matrixFeatures[cont][-1]=labelN[0]\n",
    "        cont=cont+1\n",
    "    return matrixFeatures   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5200, 164)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrixFeatures.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar dataset en un archivo csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATHSAMPLES = './training_list.txt'\n",
    "#SOUNDS =np.array(['backward','bed','cat','eight'])\n",
    "#matrixFeatures = build_features(PATHSAMPLES,SOUNDS)\n",
    "#np.savetxt('data/audiosData.csv',matrixFeatures,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
