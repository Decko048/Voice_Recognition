{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import IPython.display as ipd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import wav_to_mel_spect\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHSAMPLES = '../data/training_list.txt'\n",
    "NSAMPLES = 10\n",
    "SOUNDS =np.array(['yes','no','right','five','nine'])\n",
    "#path_out = '/home/deiry/semilleroML/Voice_Recognition/data/mel-spectrograms/'\n",
    "path_out = '/Users/deiry/ML/Voice_Recognition/data/mel-spectograms/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Path_Word_SpeakerId(NSAMPLES, PATHSAMPLES, SOUNDS):\n",
    "    ROOTPATH= 'data/'\n",
    "    data = pd.read_csv(PATHSAMPLES, sep=\" \", header=None)\n",
    "    data = data.values #Convertir en numpy array\n",
    "    labels = []\n",
    "    speakers  = []\n",
    "    paths = []\n",
    "    for path in data:\n",
    "        pathSplit =path[0].split('/')\n",
    "        speakerName = pathSplit[1].split('_')[0]\n",
    "        word = pathSplit[0]\n",
    "        isWord = np.where(SOUNDS == word)\n",
    "        if len(isWord[0]) != 0:\n",
    "            label = SOUNDS[isWord[0][0]]\n",
    "            labels.append(label)\n",
    "            speakers.append(speakerName)\n",
    "            paths.append(ROOTPATH+path[0])\n",
    "    NSAMPLES = NSAMPLES\n",
    "    first = labels.index(SOUNDS[0])\n",
    "    last = first +NSAMPLES\n",
    "    matrixMajor = np.column_stack([paths[first:last], labels[first:last], speakers[first:last]])    \n",
    "    for i in range(1,np.size(SOUNDS,0)):\n",
    "        first = labels.index(SOUNDS[i])\n",
    "        last = first +NSAMPLES\n",
    "        clasei = np.column_stack([paths[first:last], labels[first:last], speakers[first:last]])    \n",
    "        matrixMajor = np.append(matrixMajor,clasei,axis=0)\n",
    "    return matrixMajor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataset(path_word_speakerId):\n",
    "    speakers =[]\n",
    "    words = []\n",
    "    spectrograms = []\n",
    "    pos = 0\n",
    "\n",
    "     #Encode etiqueta del path audio,speaker y la palabra\n",
    "    leSpeaker = preprocessing.LabelEncoder()\n",
    "    leWord =  preprocessing.LabelEncoder()\n",
    "\n",
    "    #Encode\n",
    "    leSpeaker.fit(path_word_speakerId[:,2])\n",
    "    leWord.fit(path_word_speakerId[:,1])\n",
    "\n",
    "\n",
    "    for p in path_word_speakerId:\n",
    "        name = p[0].split('/')[-1].split('.')[0]\n",
    "        word = p[1]\n",
    "        speaker_id = p[-1]\n",
    "\n",
    "        #Transformaci√≥n del encoder\n",
    "        labelSpeaker = leSpeaker.transform([speaker_id])\n",
    "        labelWord= leWord.transform([word])     \n",
    "        wav_path = '../'+p[0]\n",
    "        spect = wavToMelSpect(wav_path, norm=True, pad=True) \n",
    "        spectrograms.append(spect)\n",
    "        speakers.append(labelSpeaker[0])\n",
    "        words.append(labelWord[0])\n",
    "        displayMelSpectogram(spect, word, pos)\n",
    "        pos+=1\n",
    "        \n",
    "    \n",
    "    return spectrograms,speakers, words\n",
    "\n",
    "\n",
    "def wavToMelSpect(wav_path,n_mels=120, norm=True, pad = True):\n",
    "    name = wav_path.split('/')[-1].split('.')[0]\n",
    "    y, sr = librosa.load(wav_path, duration=1.0)\n",
    "\n",
    "    spect, _ = librosa.effects.trim(y)\n",
    "    print(\"orignal \",spect.shape)\n",
    "              \n",
    "    spect = librosa.feature.melspectrogram(y=spect, sr=sr,n_mels=128,hop_length=512,n_fft=2048)\n",
    "    print(\"mel \",spect.shape)\n",
    "    if(pad):\n",
    "        spect = wav_to_mel_spect.pad_audio(spect) \n",
    "        \n",
    "    print(\"pad \", spect.shape)\n",
    "    if(norm):      \n",
    "        spect=sk.preprocessing.minmax_scale(spect, axis=0)      \n",
    "  \n",
    "    print(\"final\", spect.shape)\n",
    "    return spect\n",
    "\n",
    "def displayMelSpectogram(spect, word , pos):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    S_dB = librosa.power_to_db(spect, ref=np.max)\n",
    "    librosa.display.specshow(S_dB, x_axis='time',\n",
    "                             y_axis='mel', sr=22050,\n",
    "                            fmax=8000)\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Mel-frequency spectrogram word '+ str(word) + '  position'+str(pos))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_word_speakerId = get_Path_Word_SpeakerId(NSAMPLES, PATHSAMPLES, SOUNDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['data/yes/004ae714_nohash_0.wav', 'yes', '004ae714'],\n",
       "       ['data/yes/004ae714_nohash_1.wav', 'yes', '004ae714'],\n",
       "       ['data/yes/00970ce1_nohash_0.wav', 'yes', '00970ce1'],\n",
       "       ['data/yes/00f0204f_nohash_0.wav', 'yes', '00f0204f'],\n",
       "       ['data/yes/00f0204f_nohash_1.wav', 'yes', '00f0204f'],\n",
       "       ['data/yes/00f0204f_nohash_2.wav', 'yes', '00f0204f'],\n",
       "       ['data/yes/012c8314_nohash_0.wav', 'yes', '012c8314'],\n",
       "       ['data/yes/0132a06d_nohash_0.wav', 'yes', '0132a06d'],\n",
       "       ['data/yes/0132a06d_nohash_1.wav', 'yes', '0132a06d'],\n",
       "       ['data/yes/0132a06d_nohash_2.wav', 'yes', '0132a06d'],\n",
       "       ['data/no/012c8314_nohash_0.wav', 'no', '012c8314'],\n",
       "       ['data/no/0132a06d_nohash_0.wav', 'no', '0132a06d'],\n",
       "       ['data/no/0132a06d_nohash_1.wav', 'no', '0132a06d'],\n",
       "       ['data/no/0132a06d_nohash_2.wav', 'no', '0132a06d'],\n",
       "       ['data/no/0132a06d_nohash_3.wav', 'no', '0132a06d'],\n",
       "       ['data/no/0132a06d_nohash_4.wav', 'no', '0132a06d'],\n",
       "       ['data/no/0137b3f4_nohash_0.wav', 'no', '0137b3f4'],\n",
       "       ['data/no/0137b3f4_nohash_1.wav', 'no', '0137b3f4'],\n",
       "       ['data/no/0137b3f4_nohash_2.wav', 'no', '0137b3f4'],\n",
       "       ['data/no/0137b3f4_nohash_3.wav', 'no', '0137b3f4'],\n",
       "       ['data/right/00b01445_nohash_0.wav', 'right', '00b01445'],\n",
       "       ['data/right/012187a4_nohash_0.wav', 'right', '012187a4'],\n",
       "       ['data/right/012187a4_nohash_1.wav', 'right', '012187a4'],\n",
       "       ['data/right/012c8314_nohash_0.wav', 'right', '012c8314'],\n",
       "       ['data/right/012c8314_nohash_1.wav', 'right', '012c8314'],\n",
       "       ['data/right/0132a06d_nohash_0.wav', 'right', '0132a06d'],\n",
       "       ['data/right/0132a06d_nohash_1.wav', 'right', '0132a06d'],\n",
       "       ['data/right/0132a06d_nohash_2.wav', 'right', '0132a06d'],\n",
       "       ['data/right/0132a06d_nohash_3.wav', 'right', '0132a06d'],\n",
       "       ['data/right/0135f3f2_nohash_0.wav', 'right', '0135f3f2'],\n",
       "       ['data/five/004ae714_nohash_0.wav', 'five', '004ae714'],\n",
       "       ['data/five/00b01445_nohash_0.wav', 'five', '00b01445'],\n",
       "       ['data/five/00b01445_nohash_1.wav', 'five', '00b01445'],\n",
       "       ['data/five/00f0204f_nohash_0.wav', 'five', '00f0204f'],\n",
       "       ['data/five/012c8314_nohash_0.wav', 'five', '012c8314'],\n",
       "       ['data/five/012c8314_nohash_1.wav', 'five', '012c8314'],\n",
       "       ['data/five/0132a06d_nohash_0.wav', 'five', '0132a06d'],\n",
       "       ['data/five/0132a06d_nohash_1.wav', 'five', '0132a06d'],\n",
       "       ['data/five/0132a06d_nohash_2.wav', 'five', '0132a06d'],\n",
       "       ['data/five/0132a06d_nohash_3.wav', 'five', '0132a06d'],\n",
       "       ['data/nine/00b01445_nohash_0.wav', 'nine', '00b01445'],\n",
       "       ['data/nine/012c8314_nohash_0.wav', 'nine', '012c8314'],\n",
       "       ['data/nine/012c8314_nohash_1.wav', 'nine', '012c8314'],\n",
       "       ['data/nine/012c8314_nohash_2.wav', 'nine', '012c8314'],\n",
       "       ['data/nine/0132a06d_nohash_0.wav', 'nine', '0132a06d'],\n",
       "       ['data/nine/0132a06d_nohash_1.wav', 'nine', '0132a06d'],\n",
       "       ['data/nine/0132a06d_nohash_2.wav', 'nine', '0132a06d'],\n",
       "       ['data/nine/0137b3f4_nohash_0.wav', 'nine', '0137b3f4'],\n",
       "       ['data/nine/0137b3f4_nohash_1.wav', 'nine', '0137b3f4'],\n",
       "       ['data/nine/0137b3f4_nohash_2.wav', 'nine', '0137b3f4']],\n",
       "      dtype='<U32')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_word_speakerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nine = path_word_speakerId[-10:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['data/nine/00b01445_nohash_0.wav', 'nine', '00b01445'],\n",
       "       ['data/nine/012c8314_nohash_0.wav', 'nine', '012c8314'],\n",
       "       ['data/nine/012c8314_nohash_1.wav', 'nine', '012c8314'],\n",
       "       ['data/nine/012c8314_nohash_2.wav', 'nine', '012c8314'],\n",
       "       ['data/nine/0132a06d_nohash_0.wav', 'nine', '0132a06d'],\n",
       "       ['data/nine/0132a06d_nohash_1.wav', 'nine', '0132a06d'],\n",
       "       ['data/nine/0132a06d_nohash_2.wav', 'nine', '0132a06d'],\n",
       "       ['data/nine/0137b3f4_nohash_0.wav', 'nine', '0137b3f4'],\n",
       "       ['data/nine/0137b3f4_nohash_1.wav', 'nine', '0137b3f4']],\n",
       "      dtype='<U32')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orignal  (22050,)\n",
      "mel  (128, 44)\n",
      "pad  (22050, 21966)\n",
      "final (22050, 21966)\n"
     ]
    }
   ],
   "source": [
    "spectrograms,speakers, words = createDataset(nine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([spectrograms,speakers,words],index=['mel-spectrogram','speaker','word']).T\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_out = ''.join([path_out, 'mel-spectrograms_2500.hd5'])\n",
    "path_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd\n",
    "../data/mel-spectrograms_2500.hd5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_hdf('../data/mel-spectrograms_2500.hd5', key = 'description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_hdf('/Users/deiry/ML/Voice_Recognition/data/mel-spectograms/mel-spectrograms_7500.hd5', key = 'description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b = pd.read_hdf('../data/mel-spectrograms_2500.hd5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b.shape\n",
    "df = df_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = df['mel-spectrogram']\n",
    "pos = 0\n",
    "for i in range(0,len(img)):\n",
    "    spect, word , pos = img[i], df['word'][i], i\n",
    "    displayMelSpectogram(spect, word , pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
