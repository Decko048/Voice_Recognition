{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCCS\n",
    "Obtener los mfccs para 5 clases c/u de 500 audios, para un total de 15.000 audios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizar agrupaciones de 10 ventanas y promediar sus coeficientes MFCCS. Nota: el ultimo grupo de ventanas sera en varias ocasiones menor a 10, sin embargo se promediaran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import IPython.display as ipd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATHSAMPLES = '../data/training_list_test_temporal.txt'\n",
    "PATHSAMPLES = '../data/training_list.txt'\n",
    "NSAMPLES = 10\n",
    "SOUNDS =np.array(['yes','no','right','five','nine'])\n",
    "#SOUNDS =np.array(['off','five','left'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Path_Word_SpeakerId(NSAMPLES, PATHSAMPLES, SOUNDS):\n",
    "    ROOTPATH= 'data/'\n",
    "    data = pd.read_csv(PATHSAMPLES, sep=\" \", header=None)\n",
    "    data = data.values #Convertir en numpy array\n",
    "    labels = []\n",
    "    speakers  = []\n",
    "    paths = []\n",
    "    for path in data:\n",
    "        pathSplit =path[0].split('/')\n",
    "        speakerName = pathSplit[1].split('_')[0]\n",
    "        word = pathSplit[0]\n",
    "        isWord = np.where(SOUNDS == word)\n",
    "        if len(isWord[0]) != 0:\n",
    "            label = SOUNDS[isWord[0][0]]\n",
    "            labels.append(label)\n",
    "            speakers.append(speakerName)\n",
    "            paths.append(ROOTPATH+path[0])\n",
    "    NSAMPLES = NSAMPLES\n",
    "    first = labels.index(SOUNDS[0])\n",
    "    last = first +NSAMPLES\n",
    "    matrixMajor = np.column_stack([paths[first:last], labels[first:last], speakers[first:last]])    \n",
    "    for i in range(1,np.size(SOUNDS,0)):\n",
    "        first = labels.index(SOUNDS[i])\n",
    "        last = first +NSAMPLES\n",
    "        clasei = np.column_stack([paths[first:last], labels[first:last], speakers[first:last]])    \n",
    "        matrixMajor = np.append(matrixMajor,clasei,axis=0)\n",
    "    return matrixMajor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_word_speakerId = get_Path_Word_SpeakerId(NSAMPLES, PATHSAMPLES, SOUNDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 3)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_word_speakerId.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['data/yes/004ae714_nohash_0.wav', 'yes', '004ae714'],\n",
       "       ['data/yes/004ae714_nohash_1.wav', 'yes', '004ae714'],\n",
       "       ['data/yes/00970ce1_nohash_0.wav', 'yes', '00970ce1'],\n",
       "       ['data/yes/00f0204f_nohash_0.wav', 'yes', '00f0204f'],\n",
       "       ['data/yes/00f0204f_nohash_1.wav', 'yes', '00f0204f'],\n",
       "       ['data/yes/00f0204f_nohash_2.wav', 'yes', '00f0204f'],\n",
       "       ['data/yes/012c8314_nohash_0.wav', 'yes', '012c8314'],\n",
       "       ['data/yes/0132a06d_nohash_0.wav', 'yes', '0132a06d'],\n",
       "       ['data/yes/0132a06d_nohash_1.wav', 'yes', '0132a06d'],\n",
       "       ['data/yes/0132a06d_nohash_2.wav', 'yes', '0132a06d'],\n",
       "       ['data/no/012c8314_nohash_0.wav', 'no', '012c8314'],\n",
       "       ['data/no/0132a06d_nohash_0.wav', 'no', '0132a06d'],\n",
       "       ['data/no/0132a06d_nohash_1.wav', 'no', '0132a06d'],\n",
       "       ['data/no/0132a06d_nohash_2.wav', 'no', '0132a06d'],\n",
       "       ['data/no/0132a06d_nohash_3.wav', 'no', '0132a06d'],\n",
       "       ['data/no/0132a06d_nohash_4.wav', 'no', '0132a06d'],\n",
       "       ['data/no/0137b3f4_nohash_0.wav', 'no', '0137b3f4'],\n",
       "       ['data/no/0137b3f4_nohash_1.wav', 'no', '0137b3f4'],\n",
       "       ['data/no/0137b3f4_nohash_2.wav', 'no', '0137b3f4'],\n",
       "       ['data/no/0137b3f4_nohash_3.wav', 'no', '0137b3f4'],\n",
       "       ['data/right/00b01445_nohash_0.wav', 'right', '00b01445'],\n",
       "       ['data/right/012187a4_nohash_0.wav', 'right', '012187a4'],\n",
       "       ['data/right/012187a4_nohash_1.wav', 'right', '012187a4'],\n",
       "       ['data/right/012c8314_nohash_0.wav', 'right', '012c8314'],\n",
       "       ['data/right/012c8314_nohash_1.wav', 'right', '012c8314'],\n",
       "       ['data/right/0132a06d_nohash_0.wav', 'right', '0132a06d'],\n",
       "       ['data/right/0132a06d_nohash_1.wav', 'right', '0132a06d'],\n",
       "       ['data/right/0132a06d_nohash_2.wav', 'right', '0132a06d'],\n",
       "       ['data/right/0132a06d_nohash_3.wav', 'right', '0132a06d'],\n",
       "       ['data/right/0135f3f2_nohash_0.wav', 'right', '0135f3f2'],\n",
       "       ['data/five/004ae714_nohash_0.wav', 'five', '004ae714'],\n",
       "       ['data/five/00b01445_nohash_0.wav', 'five', '00b01445'],\n",
       "       ['data/five/00b01445_nohash_1.wav', 'five', '00b01445'],\n",
       "       ['data/five/00f0204f_nohash_0.wav', 'five', '00f0204f'],\n",
       "       ['data/five/012c8314_nohash_0.wav', 'five', '012c8314'],\n",
       "       ['data/five/012c8314_nohash_1.wav', 'five', '012c8314'],\n",
       "       ['data/five/0132a06d_nohash_0.wav', 'five', '0132a06d'],\n",
       "       ['data/five/0132a06d_nohash_1.wav', 'five', '0132a06d'],\n",
       "       ['data/five/0132a06d_nohash_2.wav', 'five', '0132a06d'],\n",
       "       ['data/five/0132a06d_nohash_3.wav', 'five', '0132a06d'],\n",
       "       ['data/nine/00b01445_nohash_0.wav', 'nine', '00b01445'],\n",
       "       ['data/nine/012c8314_nohash_0.wav', 'nine', '012c8314'],\n",
       "       ['data/nine/012c8314_nohash_1.wav', 'nine', '012c8314'],\n",
       "       ['data/nine/012c8314_nohash_2.wav', 'nine', '012c8314'],\n",
       "       ['data/nine/0132a06d_nohash_0.wav', 'nine', '0132a06d'],\n",
       "       ['data/nine/0132a06d_nohash_1.wav', 'nine', '0132a06d'],\n",
       "       ['data/nine/0132a06d_nohash_2.wav', 'nine', '0132a06d'],\n",
       "       ['data/nine/0137b3f4_nohash_0.wav', 'nine', '0137b3f4'],\n",
       "       ['data/nine/0137b3f4_nohash_1.wav', 'nine', '0137b3f4'],\n",
       "       ['data/nine/0137b3f4_nohash_2.wav', 'nine', '0137b3f4']],\n",
       "      dtype='<U32')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_word_speakerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(path_word_speakerId, n_mfcc,NSAMPLES, PATHSAMPLES, SOUNDS):\n",
    "    N_rows = NSAMPLES*len(SOUNDS)*n_mfcc\n",
    "    N_colums = n_mfcc +3# número de columnas del mfcc + 3 columnas (la palabra y el speaker id, path al que pertenece)\n",
    "    # el path es necesario ya que estamos teniendo un enfoque de multiples instancias.\n",
    "    path_word_speakerId = get_Path_Word_SpeakerId(NSAMPLES, PATHSAMPLES, SOUNDS)\n",
    "    matrix_features = np.empty((1,23)) # inicialmente\n",
    "\n",
    "    #Encode etiqueta del path audio,speaker y la palabra\n",
    "    lePath = preprocessing.LabelEncoder()\n",
    "    leSpeaker = preprocessing.LabelEncoder()\n",
    "    leWord =  preprocessing.LabelEncoder()\n",
    "    \n",
    "    #Encode\n",
    "    lePath.fit(path_word_speakerId[:,0])\n",
    "    leSpeaker.fit(path_word_speakerId[:,2])\n",
    "    leWord.fit(path_word_speakerId[:,1])\n",
    "    \n",
    "    #Recoremos las muestras y sacamos los MFCCS\n",
    "    \n",
    "    for sound_info in path_word_speakerId:\n",
    "        audio_path = '../'+sound_info[0]\n",
    "        x , sr = librosa.load(audio_path)\n",
    "        x_normalize=sk.preprocessing.minmax_scale(x, axis=0)       \n",
    "        #Los mfccs del audio i-esimo\n",
    "        mfccs = librosa.feature.mfcc(x_normalize, sr=sr,n_mfcc=n_mfcc,hop_length=int(0.010*sr), n_fft=int(0.025*sr))\n",
    "        \n",
    "        n_windows = mfccs.shape[1]\n",
    "        \n",
    "        n_groups = int(n_windows/10)\n",
    "        \n",
    "        n_windos_end_group = n_windows%10\n",
    "        \n",
    "        if(n_windos_end_group !=0):        \n",
    "            n_groupsT =n_groups + 1\n",
    "        else:\n",
    "            n_groupsT = n_groups\n",
    "        \n",
    "        #info sobre el audio\n",
    "        path = sound_info[0]\n",
    "        speaker_id = sound_info[2]\n",
    "        word=sound_info[1]      \n",
    "        \n",
    "        #Transformación del encoder\n",
    "        labelPath = lePath.transform([path])\n",
    "        labelSpeaker = leSpeaker.transform([speaker_id])\n",
    "        labelWord= leWord.transform([word])                \n",
    "        \n",
    "        #Repeticion de las columnas path,word,speaker, multiples instancias        \n",
    "        \n",
    "        \n",
    "        labelPath = np.repeat(labelPath,n_groupsT)\n",
    "        labelWord =  np.repeat(labelWord,n_groupsT)\n",
    "        labelSpeaker= np.repeat(labelSpeaker,n_groupsT)        \n",
    "        \n",
    "        fila_P_W_S = np.array([labelPath,labelWord,labelSpeaker]).T  \n",
    "        \n",
    "        mfccs =mfccs.T\n",
    "        \n",
    "        \n",
    "        first_wind = 0\n",
    "        last_wind =n_windows-n_windos_end_group\n",
    "        \n",
    "        avg_splis = []\n",
    "        for g in range(n_groups):\n",
    "            first_wind = g*10\n",
    "            end_wind = first_wind + 10\n",
    "            group_1 = mfccs[first_wind:end_wind,:]\n",
    "            avg_spli_group_1 = np.average(group_1,axis=0)\n",
    "            avg_splis.append(avg_spli_group_1)\n",
    "      \n",
    "        if(n_windos_end_group!=0):\n",
    "            end_group_1 = n_windows - n_windos_end_group\n",
    "            group_2 =  mfccs[end_group_1:,:]\n",
    "            avg_spli_group_2 = np.average(group_2,axis=0)\n",
    "            avg_splis.append(avg_spli_group_2)\n",
    "        \n",
    "        mfccFull =  np.hstack((avg_splis,fila_P_W_S))\n",
    "        \n",
    "        \n",
    "        matrix_features = np.concatenate((matrix_features,mfccFull), axis=0) \n",
    "                   \n",
    "    return matrix_features[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(540, 23)\n"
     ]
    }
   ],
   "source": [
    "matrixFinal = build_features(path_word_speakerId, 20,NSAMPLES, PATHSAMPLES, SOUNDS)\n",
    "print(matrixFinal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('../data/audios_MFCC_average.csv',matrixFinal,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
