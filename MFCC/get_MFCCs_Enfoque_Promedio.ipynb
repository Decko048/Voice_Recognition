{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCCS\n",
    "Obtener los mfccs para 5 clases c/u de 500 audios, para un total de 15.000 audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import IPython.display as ipd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATHSAMPLES = '../data/training_list_test_temporal.txt'\n",
    "PATHSAMPLES = '../data/training_list.txt'\n",
    "NSAMPLES = 1000\n",
    "SOUNDS =np.array(['yes','no','right','five','nine'])\n",
    "#SOUNDS =np.array(['off','five','left'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Path_Word_SpeakerId(NSAMPLES, PATHSAMPLES, SOUNDS):\n",
    "    ROOTPATH= 'data/'\n",
    "    data = pd.read_csv(PATHSAMPLES, sep=\" \", header=None)\n",
    "    data = data.values #Convertir en numpy array\n",
    "    labels = []\n",
    "    speakers  = []\n",
    "    paths = []\n",
    "    for path in data:\n",
    "        pathSplit =path[0].split('/')\n",
    "        speakerName = pathSplit[1].split('_')[0]\n",
    "        word = pathSplit[0]\n",
    "        isWord = np.where(SOUNDS == word)\n",
    "        if len(isWord[0]) != 0:\n",
    "            label = SOUNDS[isWord[0][0]]\n",
    "            labels.append(label)\n",
    "            speakers.append(speakerName)\n",
    "            paths.append(ROOTPATH+path[0])\n",
    "    NSAMPLES = NSAMPLES\n",
    "    first = labels.index(SOUNDS[0])\n",
    "    last = first +NSAMPLES\n",
    "    matrixMajor = np.column_stack([paths[first:last], labels[first:last], speakers[first:last]])    \n",
    "    for i in range(1,np.size(SOUNDS,0)):\n",
    "        first = labels.index(SOUNDS[i])\n",
    "        last = first +NSAMPLES\n",
    "        clasei = np.column_stack([paths[first:last], labels[first:last], speakers[first:last]])    \n",
    "        matrixMajor = np.append(matrixMajor,clasei,axis=0)\n",
    "    return matrixMajor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_word_speakerId = get_Path_Word_SpeakerId(NSAMPLES, PATHSAMPLES, SOUNDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 3)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_word_speakerId.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['data/yes/004ae714_nohash_0.wav', 'yes', '004ae714'],\n",
       "       ['data/yes/004ae714_nohash_1.wav', 'yes', '004ae714'],\n",
       "       ['data/yes/00970ce1_nohash_0.wav', 'yes', '00970ce1'],\n",
       "       ...,\n",
       "       ['data/nine/4e99c1b7_nohash_1.wav', 'nine', '4e99c1b7'],\n",
       "       ['data/nine/4e99c1b7_nohash_2.wav', 'nine', '4e99c1b7'],\n",
       "       ['data/nine/4e99c1b7_nohash_3.wav', 'nine', '4e99c1b7']],\n",
       "      dtype='<U33')"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_word_speakerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(path_word_speakerId, n_mfcc,NSAMPLES, PATHSAMPLES, SOUNDS):\n",
    "    N_rows = NSAMPLES*len(SOUNDS)*n_mfcc\n",
    "    N_colums = n_mfcc +3# nÃºmero de columnas del mfcc + 3 columnas (la palabra y el speaker id, path al que pertenece)\n",
    "    # el path es necesario ya que estamos teniendo un enfoque de multiples instancias.\n",
    "    path_word_speakerId = get_Path_Word_SpeakerId(NSAMPLES, PATHSAMPLES, SOUNDS)\n",
    "    matrix_features = np.empty((1,23)) # inicialmente\n",
    "\n",
    "    #Encode etiqueta del audio,speaker y la palabra\n",
    "    lePath = preprocessing.LabelEncoder()\n",
    "    leSpeaker = preprocessing.LabelEncoder()\n",
    "    leWord =  preprocessing.LabelEncoder()\n",
    "    \n",
    "    lePath.fit(path_word_speakerId[:,0])\n",
    "    leSpeaker.fit(path_word_speakerId[:,2])\n",
    "    leWord.fit(path_word_speakerId[:,1])\n",
    "    \n",
    "        \n",
    "    for sound_info in path_word_speakerId:\n",
    "        audio_path = '../'+sound_info[0]\n",
    "        x , sr = librosa.load(audio_path)\n",
    "        x_normalize=sk.preprocessing.minmax_scale(x, axis=0)       \n",
    "        mfccs = librosa.feature.mfcc(x_normalize, sr=sr,n_mfcc=n_mfcc,hop_length=int(0.010*sr), n_fft=int(0.025*sr))\n",
    "        n_windows = mfccs.shape[1]\n",
    "        path = sound_info[0]\n",
    "        speaker_id = sound_info[2]\n",
    "        word=sound_info[1]        \n",
    "        labelPath = lePath.transform([path])\n",
    "        labelSpeaker = leSpeaker.transform([speaker_id])\n",
    "        labelWord= leWord.transform([word])                \n",
    "        labelPath = np.repeat(labelPath,10)\n",
    "        labelWord =  np.repeat(labelWord,10)\n",
    "        labelSpeaker= np.repeat(labelSpeaker,10)        \n",
    "        fila_P_W_S = np.array([labelPath,labelWord,labelSpeaker]).T  \n",
    "        #mfccFull =  np.hstack((mfccs.T,fila_P_W_S)) \n",
    "        #Selecciona de 10 y se promedian\n",
    "        mfccFull_split = np.array_split(mfccs.T,10)\n",
    "        avg_splis = np.ones((10,20))\n",
    "        i = 0\n",
    "        for spli in mfccFull_split:\n",
    "            avg_spli = np.average(spli,axis=0)            \n",
    "            avg_splis[i]=avg_spli\n",
    "            i = i+1\n",
    "        mfccFull =  np.hstack((avg_splis,fila_P_W_S))\n",
    "        \n",
    "        matrix_features = np.concatenate((matrix_features,mfccFull), axis=0)        \n",
    "    return matrix_features[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 23)\n"
     ]
    }
   ],
   "source": [
    "matrixFinal = build_features(path_word_speakerId, 20,NSAMPLES, PATHSAMPLES, SOUNDS)\n",
    "print(matrixFinal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('../data/audios_MFCC_average.csv',matrixFinal,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 23)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_avg = pd.read_csv('../data/audios_MFCC_average.csv', sep=\",\", header=None)\n",
    "data_avg = data_avg.values #Convertir en numpy array\n",
    "data_avg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
