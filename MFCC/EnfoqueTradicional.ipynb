{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enfoque 1, Estadísticos de alto orden, medias y desviaciones estándar (Enfoque tradicional)\n",
    "\n",
    "\n",
    "Por cada muestra crear un vector de (1,80), donde 80 son:\n",
    "- Las medias de los 20 coeficientes MFCC de todas las ventanas.\n",
    "- Las desviaciones estándar de los 20 coeficientes MFCC de todas las ventanas.\n",
    "- Los Kurtosis de los 20 coeficientes MFCC de todas las ventanas.\n",
    "- Los skewness de los 20 coeficientes MFCC de todas las ventanas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import IPython.display as ipd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import skew\n",
    "\n",
    "from scipy.stats import kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATHSAMPLES = '../data/training_list_test_temporal.txt'\n",
    "PATHSAMPLES = '../data/training_list.txt'\n",
    "NSAMPLES= 1000\n",
    "SOUNDS =np.array(['yes','no','right','five','nine'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Path_Word_SpeakerId(NSAMPLES, PATHSAMPLES, SOUNDS):\n",
    "    ROOTPATH= 'data/'\n",
    "    data = pd.read_csv(PATHSAMPLES, sep=\" \", header=None)\n",
    "    data = data.values #Convertir en numpy array\n",
    "    labels = []\n",
    "    speakers  = []\n",
    "    paths = []\n",
    "    for path in data:\n",
    "        pathSplit =path[0].split('/')\n",
    "        speakerName = pathSplit[1].split('_')[0]\n",
    "        word = pathSplit[0]\n",
    "        isWord = np.where(SOUNDS == word)\n",
    "        if len(isWord[0]) != 0:\n",
    "            label = SOUNDS[isWord[0][0]]\n",
    "            labels.append(label)\n",
    "            speakers.append(speakerName)\n",
    "            paths.append(ROOTPATH+path[0])\n",
    "    NSAMPLES = NSAMPLES\n",
    "    first = labels.index(SOUNDS[0])\n",
    "    last = first +NSAMPLES\n",
    "    matrixMajor = np.column_stack([paths[first:last], labels[first:last], speakers[first:last]])    \n",
    "    for i in range(1,np.size(SOUNDS,0)):\n",
    "        first = labels.index(SOUNDS[i])\n",
    "        last = first +NSAMPLES\n",
    "        clasei = np.column_stack([paths[first:last], labels[first:last], speakers[first:last]])    \n",
    "        matrixMajor = np.append(matrixMajor,clasei,axis=0)\n",
    "    \n",
    "\n",
    "    \n",
    "    return matrixMajor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['data/yes/004ae714_nohash_0.wav', 'yes', '004ae714'],\n",
       "       ['data/yes/004ae714_nohash_1.wav', 'yes', '004ae714'],\n",
       "       ['data/yes/00970ce1_nohash_0.wav', 'yes', '00970ce1'],\n",
       "       ...,\n",
       "       ['data/nine/4e99c1b7_nohash_1.wav', 'nine', '4e99c1b7'],\n",
       "       ['data/nine/4e99c1b7_nohash_2.wav', 'nine', '4e99c1b7'],\n",
       "       ['data/nine/4e99c1b7_nohash_3.wav', 'nine', '4e99c1b7']],\n",
       "      dtype='<U33')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_word_speakerId = get_Path_Word_SpeakerId(NSAMPLES, PATHSAMPLES, SOUNDS)\n",
    "path_word_speakerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_word_speakerId.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(path_word_speakerId, n_mfcc,NSAMPLES, PATHSAMPLES, SOUNDS):\n",
    "    N_rows = NSAMPLES*len(SOUNDS)*n_mfcc\n",
    "    N_colums = n_mfcc +3# número de columnas del mfcc + 3 columnas (la palabra y el speaker id, path al que pertenece)\n",
    "    # el path es necesario ya que estamos teniendo un enfoque de multiples instancias.\n",
    "    path_word_speakerId = get_Path_Word_SpeakerId(NSAMPLES, PATHSAMPLES, SOUNDS)\n",
    "    matrix_features = np.empty((1,n_mfcc*4 +2)) # inicialmente\n",
    "\n",
    "    #Encode etiqueta del audio,speaker y la palabra\n",
    "    lePath = preprocessing.LabelEncoder()\n",
    "    leSpeaker = preprocessing.LabelEncoder()\n",
    "    leWord =  preprocessing.LabelEncoder()\n",
    "    \n",
    "    lePath.fit(path_word_speakerId[:,0])\n",
    "    leSpeaker.fit(path_word_speakerId[:,2])\n",
    "    leWord.fit(path_word_speakerId[:,1])\n",
    "    \n",
    "        \n",
    "    for sound_info in path_word_speakerId:\n",
    "        audio_path = '../'+sound_info[0]\n",
    "        x , sr = librosa.load(audio_path)\n",
    "        x_normalize=sk.preprocessing.minmax_scale(x, axis=0)       \n",
    "        mfccs = librosa.feature.mfcc(x_normalize, sr=sr,n_mfcc=n_mfcc,hop_length=int(0.010*sr), n_fft=int(0.025*sr))\n",
    "        mfccs = mfccs.T\n",
    "      \n",
    "        \n",
    "        mean_mfccs = np.mean(mfccs, axis=0)\n",
    "        mean_mfccs = np.reshape(mean_mfccs, (mean_mfccs.shape[0],1))\n",
    "        \n",
    "        std_mfcss = np.std(mfccs, axis=0)\n",
    "        std_mfcss = np.reshape(std_mfcss,(std_mfcss.shape[0],1))\n",
    " \n",
    "        \n",
    "        skew_mfccs = skew(mfccs)\n",
    "        skew_mfccs = np.reshape(skew_mfccs, (skew_mfccs.shape[0],1))\n",
    "        \n",
    "        kurt_mfcss = kurtosis(mfccs)\n",
    "        kurt_mfcss = np.reshape(kurt_mfcss, (kurt_mfcss.shape[0],1))\n",
    "       \n",
    "        mfccFull =  np.hstack((mean_mfccs.flatten(),std_mfcss.flatten(),skew_mfccs.flatten(),kurt_mfcss.flatten()))\n",
    "        mfccFull = np.reshape(mfccFull, (1,mfccFull.shape[0]))\n",
    "        \n",
    "   \n",
    "        n_windows = mfccs.shape[1]\n",
    "        \n",
    "        speaker_id = sound_info[2]\n",
    "        word=sound_info[1]        \n",
    "        \n",
    "        labelSpeaker = leSpeaker.transform([speaker_id])\n",
    "        labelWord= leWord.transform([word])   \n",
    "           \n",
    "        fila_P_W_S = np.array([labelWord,labelSpeaker])  \n",
    "        fila_P_W_S =fila_P_W_S.T\n",
    "     \n",
    "        mfccFull =  np.hstack((mfccFull,fila_P_W_S))      \n",
    "        matrix_features = np.concatenate((matrix_features,mfccFull), axis=0)    \n",
    "       \n",
    "    return matrix_features[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 82)\n"
     ]
    }
   ],
   "source": [
    "matrixFinal = build_features(path_word_speakerId, 20,NSAMPLES, PATHSAMPLES, SOUNDS)\n",
    "print(matrixFinal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('../data/audios_MFCC_traditional.csv',matrixFinal,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 82)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_avg = pd.read_csv('../data/audios_MFCC_traditional.csv', sep=\",\", header=None)\n",
    "data_avg = data_avg.values #Convertir en numpy array\n",
    "data_avg.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
