{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import IPython.display as ipd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy_indexed as npi\n",
    "from scipy.stats import skew\n",
    "\n",
    "from scipy.stats import kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHSAMPLES = '../data/training_list.txt'\n",
    "NSAMPLES= 1000\n",
    "SOUNDS =np.array(['yes','no','right','five','nine'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Path_Word_SpeakerId(NSAMPLES, PATHSAMPLES, SOUNDS):\n",
    "    ROOTPATH= 'data/'\n",
    "    data = pd.read_csv(PATHSAMPLES, sep=\" \", header=None)\n",
    "    data = data.values #Convertir en numpy array\n",
    "    labels = []\n",
    "    speakers  = []\n",
    "    paths = []\n",
    "    for path in data:\n",
    "        pathSplit =path[0].split('/')\n",
    "        speakerName = pathSplit[1].split('_')[0]\n",
    "        word = pathSplit[0]\n",
    "        isWord = np.where(SOUNDS == word)\n",
    "        if len(isWord[0]) != 0:\n",
    "            label = SOUNDS[isWord[0][0]]\n",
    "            labels.append(label)\n",
    "            speakers.append(speakerName)\n",
    "            paths.append(ROOTPATH+path[0])\n",
    "    NSAMPLES = NSAMPLES\n",
    "    first = labels.index(SOUNDS[0])\n",
    "    last = first +NSAMPLES\n",
    "    matrixMajor = np.column_stack([paths[first:last], labels[first:last], speakers[first:last]])    \n",
    "    for i in range(1,np.size(SOUNDS,0)):\n",
    "        first = labels.index(SOUNDS[i])\n",
    "        last = first +NSAMPLES\n",
    "        clasei = np.column_stack([paths[first:last], labels[first:last], speakers[first:last]])    \n",
    "        matrixMajor = np.append(matrixMajor,clasei,axis=0)\n",
    "    \n",
    "\n",
    "    \n",
    "    return matrixMajor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(n_mfcc,NSAMPLES, PATHSAMPLES, SOUNDS, n_groups=10):\n",
    "    N_rows = NSAMPLES*len(SOUNDS)*n_mfcc\n",
    "    N_colums = n_mfcc +3# n√∫mero de columnas del mfcc + 3 columnas (la palabra y el speaker id, path al que pertenece)\n",
    "    # el path es necesario ya que estamos teniendo un enfoque de multiples instancias.\n",
    "    path_word_speakerId = get_Path_Word_SpeakerId(NSAMPLES, PATHSAMPLES, SOUNDS)\n",
    "\n",
    "    matrix_features = np.empty((1,n_groups*n_mfcc+2)) # inicialmente\n",
    "\n",
    "    #Encode etiqueta del audio,speaker y la palabra\n",
    "    lePath = preprocessing.LabelEncoder()\n",
    "    leSpeaker = preprocessing.LabelEncoder()\n",
    "    leWord =  preprocessing.LabelEncoder()\n",
    "    \n",
    "    lePath.fit(path_word_speakerId[:,0])\n",
    "    leSpeaker.fit(path_word_speakerId[:,2])\n",
    "    leWord.fit(path_word_speakerId[:,1])\n",
    "    \n",
    "        \n",
    "    for sound_info in path_word_speakerId:\n",
    "        audio_path = '../'+sound_info[0]\n",
    "        x , sr = librosa.load(audio_path)\n",
    "        x_normalize=sk.preprocessing.minmax_scale(x, axis=0)       \n",
    "        mfccs = librosa.feature.mfcc(x_normalize, sr=sr,n_mfcc=n_mfcc,hop_length=int(0.010*sr), n_fft=int(0.025*sr))\n",
    "        mfccs = mfccs.T\n",
    "        \n",
    "        sliceM = mfccs.shape[0]//n_groups\n",
    "          \n",
    "        split_mean = np.array([np.mean(arr, axis=0) for arr in np.array(np.array_split(mfccs, n_groups))])\n",
    "        split_mean = np.reshape(split_mean, (1, split_mean.flatten().shape[0]))\n",
    "\n",
    "        \n",
    "        speaker_id = sound_info[2]\n",
    "        word=sound_info[1]        \n",
    "        \n",
    "        labelSpeaker = leSpeaker.transform([speaker_id])\n",
    "        labelWord= leWord.transform([word])   \n",
    "           \n",
    "        fila_P_W_S = np.array([labelWord,labelSpeaker])  \n",
    "        fila_P_W_S =fila_P_W_S.T\n",
    "        \n",
    "        mfccFull =  np.hstack((split_mean,fila_P_W_S))   \n",
    "    \n",
    "        matrix_features = np.concatenate((matrix_features,mfccFull), axis=0)   \n",
    "        \n",
    "    return matrix_features[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 202)\n"
     ]
    }
   ],
   "source": [
    "matrixFinal = build_features(20,NSAMPLES, PATHSAMPLES, SOUNDS)\n",
    "print(matrixFinal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('../data/audios_MFCC_Flatten_Means.csv',matrixFinal,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 202)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_avg = pd.read_csv('../data/audios_MFCC_Flatten_Means.csv', sep=\",\", header=None)\n",
    "data_avg = data_avg.values #Convertir en numpy array\n",
    "data_avg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
