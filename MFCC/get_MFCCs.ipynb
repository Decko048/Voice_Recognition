{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCCS\n",
    "Obtener los mfccs para 5 clases c/u de 500 audios, para un total de 15.000 audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import IPython.display as ipd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHSAMPLES = '../data/training_list_test_temporal.txt'\n",
    "#PATHSAMPLES = '../data/training_list.txt'\n",
    "NSAMPLES = 3\n",
    "#SOUNDS =np.array(['yes','no','right','five','nine'])\n",
    "SOUNDS =np.array(['off','five','left'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Path_Word_SpeakerId(NSAMPLES, PATHSAMPLES, SOUNDS):\n",
    "    ROOTPATH= 'data/audios_test/'\n",
    "    data = pd.read_csv(PATHSAMPLES, sep=\" \", header=None)\n",
    "    data = data.values #Convertir en numpy array\n",
    "    labels = []\n",
    "    speakers  = []\n",
    "    paths = []\n",
    "    for path in data:\n",
    "        pathSplit =path[0].split('/')\n",
    "        speakerName = pathSplit[1].split('_')[0]\n",
    "        word = pathSplit[0]\n",
    "        isWord = np.where(SOUNDS == word)\n",
    "        if len(isWord[0]) != 0:\n",
    "            label = SOUNDS[isWord[0][0]]\n",
    "            labels.append(label)\n",
    "            speakers.append(speakerName)\n",
    "            paths.append(ROOTPATH+path[0])\n",
    "    NSAMPLES = NSAMPLES\n",
    "    first = labels.index(SOUNDS[0])\n",
    "    last = first +NSAMPLES\n",
    "    matrixMajor = np.column_stack([paths[first:last], labels[first:last], speakers[first:last]])    \n",
    "    for i in range(1,np.size(SOUNDS,0)):\n",
    "        first = labels.index(SOUNDS[i])\n",
    "        last = first +NSAMPLES\n",
    "        clasei = np.column_stack([paths[first:last], labels[first:last], speakers[first:last]])    \n",
    "        matrixMajor = np.append(matrixMajor,clasei,axis=0)\n",
    "    return matrixMajor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_word_speakerId = get_Path_Word_SpeakerId(NSAMPLES, PATHSAMPLES, SOUNDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 3)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_word_speakerId.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['data/audios_test/off/0a2b400e_nohash_0.wav', 'off', '0a2b400e'],\n",
       "       ['data/audios_test/off/0a2b400e_nohash_1.wav', 'off', '0a2b400e'],\n",
       "       ['data/audios_test/off/0a2b400e_nohash_2.wav', 'off', '0a2b400e'],\n",
       "       ['data/audios_test/five/0a2b400e_nohash_0.wav', 'five',\n",
       "        '0a2b400e'],\n",
       "       ['data/audios_test/five/0a2b400e_nohash_1.wav', 'five',\n",
       "        '0a2b400e'],\n",
       "       ['data/audios_test/five/0a2b400e_nohash_2.wav', 'five',\n",
       "        '0a2b400e'],\n",
       "       ['data/audios_test/left/0a2b400e_nohash_0.wav', 'left',\n",
       "        '0a2b400e'],\n",
       "       ['data/audios_test/left/0a2b400e_nohash_1.wav', 'left',\n",
       "        '0a2b400e'],\n",
       "       ['data/audios_test/left/0a2b400e_nohash_2.wav', 'left',\n",
       "        '0a2b400e']], dtype='<U43')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_word_speakerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(path_word_speakerId, n_mfcc,NSAMPLES, PATHSAMPLES, SOUNDS):\n",
    "    N_rows = NSAMPLES*len(SOUNDS)*n_mfcc\n",
    "    N_colums = n_mfcc +3# nÃºmero de columnas del mfcc + 3 columnas (la palabra y el speaker id, path al que pertenece)\n",
    "    # el path es necesario ya que estamos teniendo un enfoque de multiples instancias.\n",
    "    path_word_speakerId = get_Path_Word_SpeakerId(NSAMPLES, PATHSAMPLES, SOUNDS)\n",
    "    matrix_features = np.empty((1,23)) # inicialmente\n",
    "\n",
    "    #Encode etiqueta del audio,speaker y la palabra\n",
    "    lePath = preprocessing.LabelEncoder()\n",
    "    leSpeaker = preprocessing.LabelEncoder()\n",
    "    leWord =  preprocessing.LabelEncoder()\n",
    "    \n",
    "    lePath.fit(path_word_speakerId[:,0])\n",
    "    leSpeaker.fit(path_word_speakerId[:,2])\n",
    "    leWord.fit(path_word_speakerId[:,1])\n",
    "    \n",
    "        \n",
    "    for sound_info in path_word_speakerId:\n",
    "        audio_path = '../'+sound_info[0]\n",
    "        x , sr = librosa.load(audio_path)\n",
    "        x_normalize=sk.preprocessing.minmax_scale(x, axis=0)       \n",
    "        mfccs = librosa.feature.mfcc(x_normalize, sr=sr,n_mfcc=n_mfcc,hop_length=int(0.010*sr), n_fft=int(0.025*sr))\n",
    "        n_windows = mfccs.shape[1]\n",
    "        path = sound_info[0]\n",
    "        speaker_id = sound_info[2]\n",
    "        word=sound_info[1]        \n",
    "        labelPath = lePath.transform([path])\n",
    "        labelSpeaker = leSpeaker.transform([speaker_id])\n",
    "        labelWord= leWord.transform([word])                \n",
    "        labelPath = np.repeat(labelPath,n_windows)\n",
    "        labelWord =  np.repeat(labelWord,n_windows)\n",
    "        labelSpeaker= np.repeat(labelSpeaker,n_windows)        \n",
    "        fila_P_W_S = np.array([labelPath,labelWord,labelSpeaker]).T        \n",
    "        mfccFull =  np.hstack((mfccs.T,fila_P_W_S))        \n",
    "        matrix_features = np.concatenate((matrix_features,mfccFull), axis=0)        \n",
    "    return matrix_features[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(909, 23)\n"
     ]
    }
   ],
   "source": [
    "matrixFinal = build_features(path_word_speakerId, 20,NSAMPLES, PATHSAMPLES, SOUNDS)\n",
    "print(matrixFinal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(909, 23)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrixFinal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-657.64953613,   19.85280228,   19.83027458, ...,    6.        ,\n",
       "           2.        ,    0.        ],\n",
       "       [-657.64953613,   19.85275841,   19.83023071, ...,    6.        ,\n",
       "           2.        ,    0.        ],\n",
       "       [-657.64953613,   19.8527565 ,   19.8302269 , ...,    6.        ,\n",
       "           2.        ,    0.        ],\n",
       "       ...,\n",
       "       [-660.11584473,   21.35703278,   20.38794899, ...,    5.        ,\n",
       "           1.        ,    0.        ],\n",
       "       [-659.33129883,   22.92096329,   22.72964859, ...,    5.        ,\n",
       "           1.        ,    0.        ],\n",
       "       [-659.78820801,   22.10509109,   21.59470749, ...,    5.        ,\n",
       "           1.        ,    0.        ]])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrixFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('data/audios_MFCC.csv',matrixFinal,delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
